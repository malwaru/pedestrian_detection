{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbebf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Essential imports\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import joblib\n",
    "import cv2\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import copy \n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99548a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SvmTrainer():\n",
    "    def __init__(self):\n",
    "        ## Default values\n",
    "        print(f\"Staring the Classifier\")\n",
    "        self.train_data=[]\n",
    "        self.train_labels=[]\n",
    "        self.classifier=LinearSVC()\n",
    "    \n",
    "    def load_train_data(self,file_path,data_type=\"*.png\",data_class=1):\n",
    "        '''\n",
    "        Load the images from the filepath and get the HoG featues\n",
    "        If dataclass=1 positive images \n",
    "        If dataclass=0 negative images\n",
    "        '''\n",
    "        files_found=False\n",
    "        for filename in glob.glob(os.path.join(file_path,data_type)):\n",
    "            files_found=True\n",
    "            current_image=cv2.imread(filename)\n",
    "            current_image=cv2.resize(current_image,(64,128))\n",
    "            cv2.imshow(\"test\",current_image)\n",
    "            current_image=cv2.cvtColor(current_image,cv2.COLOR_BGR2GRAY)\n",
    "            hog_features=hog(image=current_image,orientations=9,pixels_per_cell=(8,8),visualize=False,cells_per_block=(3,3))\n",
    "            self.train_data.append(hog_features)\n",
    "            self.train_labels.append(data_class)\n",
    "            \n",
    "        if files_found:\n",
    "            print(f\" HoG Feature extractor complete\")\n",
    "        else:\n",
    "            raise Exception(\"No such file or folder\")\n",
    "            \n",
    "    def train_svm(self,model_save_path=\"./\"):\n",
    "        '''\n",
    "        This function calls for training the data set\n",
    "        '''\n",
    "        ## Asserts if there are training data\n",
    "        assert len(self.train_data)>0,f\"No training data available\"\n",
    "        # Convert to numpy arrays\n",
    "        self.train_data = np.float32(self.train_data)\n",
    "        self.train_labels= np.array(self.train_labels)\n",
    "        #Fitting the data\n",
    "        self.classifier.fit(self.train_data,self.train_labels)\n",
    "        print(f\"Training complete saving model at {model_save_path}\")\n",
    "        now = datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "        model_name=model_save_path+\"svm_model_\"+dt_string+\".dat\"\n",
    "        joblib.dump(self.classifier,model_name)\n",
    "        print(f\"Model saved as at {model_name}\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c5d32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PersonDetecor():\n",
    "    def __init__(self,path_test: str,path_anno: str,model_path:str)-> None:\n",
    "        '''\n",
    "        Initiate the person detector class\n",
    "        \n",
    "        Params\n",
    "        ----------\n",
    "        path_test : Relative file path with the test images\n",
    "        path_anno : Relative path with the annotations \n",
    "        '''\n",
    "        self.path_test=path_test\n",
    "        self.path_anno=path_anno\n",
    "        self.downscale_factor=1.5\n",
    "        self.classifier=joblib.load(model_path)\n",
    "        # Size of the detections used in training \n",
    "        self.detect_size=(64,128)\n",
    "        self.step_size=(10,10)\n",
    "        ## The confusion matrix\n",
    "        ## TP,FP | FN , TN\n",
    "        self.CM=[[0,0],[0,0]]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def nms(self):\n",
    "        '''\n",
    "        Fast Non-maximum-supression method based on Malisiewicz et al \n",
    "                    \n",
    "        \n",
    "        \n",
    "        References:\n",
    "        The https://github.com/quantombone/exemplarsvm\n",
    "        https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/\n",
    "        https://pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "        https://nms.readthedocs.io/en/latest/_modules/nms/malisiewicz.html\n",
    "        '''\n",
    "        \n",
    "        raise NotImplementedError(\"Please implement the method\")\n",
    "        \n",
    "    def metrics(self,detections,ground_truths):\n",
    "        '''\n",
    "        Calculate the performance metrics of the method \n",
    "        \n",
    "        Measure following metrics         \n",
    "            meanAveragePrecision\n",
    "            average IoU\n",
    "            \n",
    "            \n",
    "        References:\n",
    "        https://towardsdatascience.com/on-object-detection-metrics-with-worked-example-216f173ed31e\n",
    "        https://www.v7labs.com/blog/mean-average-precision\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        ##IOU calculation\n",
    "        for detection in detections:            \n",
    "            x_mid=detection[0]+detection[2]/2\n",
    "            y_mid=detection[1]+detection[3]/2\n",
    "        for gt in ground_truths:\n",
    "            gt=0\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        raise NotImplementedError(\"Implement me\")\n",
    "        \n",
    "    def sliding_window(self,image,window_size,step_size):\n",
    "        ''''\n",
    "        Sliding window approach to pass throught the image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        window_size: Tuple (1x2)\n",
    "                    The size of the window\n",
    "        \n",
    "        step_size : Tuple(1x2)\n",
    "                            \n",
    "        \n",
    "                        the size of the window that wil p \n",
    "        Returns\n",
    "        -------\n",
    "        x : ndarray, shape Q\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        for y in range(0,image.shape[0]-window_size[1],step_size[1]):\n",
    "            for x in range(0,image.shape[1]-window_size[0],step_size[0]):\n",
    "                yield (x,y,image[y:y+window_size[1],x:x+window_size[0]])      \n",
    "        \n",
    "        \n",
    "    def visualise(self,image,bBoxs,confidence):\n",
    "        '''\n",
    "        Visualise the result bBox on image\n",
    "        '''\n",
    "        \n",
    "        for bBox in bBoxs:        \n",
    "            cv2.rectangle(image,(bBox[0],bBox[1]),(bBox[2],bBox[3]),(0,0,255),2)\n",
    "            # cv2.putText(image,\"Confidence: \"+str(confidence),(bBox[0],bBox[2]-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "            # figsize=(25,10)\n",
    "        figure1=plt.figure()\n",
    "        ax1=figure1.add_subplot(111)\n",
    "        ax1.imshow(image)\n",
    "        ax1.set(title=\"Prediction\",xlabel=\"X\",ylabel=\"Y\")     \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def add_padding(self,image):\n",
    "        '''\n",
    "        Add padding to the edges if the image is not of the right shape\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        top=0\n",
    "        btm=0\n",
    "        lft=0\n",
    "        rht=0\n",
    "        \n",
    "        if ((image.shape[1])%(self.detect_size[0]) != 0):\n",
    "            miss_pixels_x=image.shape[1]-(np.floor(image.shape[1]/self.detect_size[0])*self.detect_size[0])\n",
    "            rht=miss_pixels_x\n",
    "            \n",
    "        if ((image.shape[1])%(self.detect_size[0]) != 0):\n",
    "            miss_pixels_y=image.shape[0]-(np.floor(image.shape[0]/self.detect_size[1])*self.detect_size[1])\n",
    "            btm=miss_pixels_y \n",
    "            \n",
    "\n",
    "        \n",
    "        return cv2.copyMakeBorder(image, top, btm, lft, rht, cv2.BORDER_CONSTANT, None, value = 0)       \n",
    "        \n",
    "    \n",
    "                \n",
    "    def detect_persons_single(self,file_name: str,metrics:bool=False,visualise:bool=False)-> None:\n",
    "        '''\n",
    "        Detect people in a single image\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        data_type: string\n",
    "                    the data type of images eg: png,jpeg\n",
    "        metrics  : bool\n",
    "                    Boolean to calculate metrics\n",
    "        visualise : bool\n",
    "                    Visualise the results\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "        filename =os.path.join(self.path_test,file_name)\n",
    "        current_detections=[]\n",
    "        current_scale=0\n",
    "        current_image=cv2.imread(filename)\n",
    "        current_image=cv2.cvtColor(current_image,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        current_image=cv2.resize(current_image,(400,256))\n",
    " \n",
    "\n",
    "        for scaled_image in pyramid_gaussian(current_image,downscale=self.downscale_factor):\n",
    "            if scaled_image.shape[0]<self.detect_size[0] or scaled_image.shape[1]<self.detect_size[1]:\n",
    "                #Loop breaks when the the scale reaches smaller than the images\n",
    "                # that was used to train the classifier\n",
    "                break\n",
    "            for (x,y,cropped_image) in self.sliding_window(scaled_image,self.detect_size,self.step_size):      \n",
    "                hog_feature=hog(cropped_image,\n",
    "                            orientations=9,\n",
    "                            pixels_per_cell=(8, 8),\n",
    "                            cells_per_block=(3, 3))\n",
    "                # Flatten the features\n",
    "                \n",
    "                hog_feature=hog_feature.reshape(1,-1)\n",
    "                # Pass it through the trained model\n",
    "                try:\n",
    "                    prediction=self.classifier.predict(hog_feature)\n",
    "                except:                    \n",
    "                    print(f\"Error in prediction\")\n",
    "                    continue\n",
    "                current_confidence=self.classifier.decision_function(hog_feature)\n",
    "\n",
    "                ##If person is detected with a confidence over 50%\n",
    "                if (prediction==1) and (current_confidence>0.5):\n",
    "                        x=int(x * (self.downscale_factor**current_scale))\n",
    "                        y=int(y* (self.downscale_factor**current_scale))\n",
    "                        w=int(self.detect_size[0]*(self.downscale_factor**current_scale))\n",
    "                        h=int(self.detect_size[1]*(self.downscale_factor**current_scale))\n",
    "                        current_detections.append((x,y,w,h,current_confidence))\n",
    "            current_scale+=1\n",
    "        #End of current image detections\n",
    "        # If there are detections look work on the non max supression \n",
    "        max_box=[]\n",
    "        if len(current_detections)>0:                \n",
    "            bBoxs=np.array([[x,y,x+w,y+h] for (x,y,w,h,_) in current_detections])\n",
    "            confidences=np.array([conf[0] for (_,_,_,_,conf) in current_detections])\n",
    "            max_box=non_max_suppression(bBoxs,probs=confidences,overlapThresh=0.5)\n",
    "            \n",
    "\n",
    "        if visualise and (len(max_box)>0):\n",
    "            self.visualise(current_image,max_box,np.max(confidences))\n",
    "        else:\n",
    "            print(f\"No humans found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27846059-d806-4925-8dea-fa0f25a71875",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the trainer\n",
    "trainer=SvmTrainer()\n",
    "##data paths\n",
    "postive_sample_path=\"./data/svm_data/positive\"\n",
    "negative_sample_path=\"./data/svm_data/negative\"\n",
    "##Loading positive data\n",
    "trainer.load_train_data(file_path=postive_sample_path,data_type=\"*.png\",data_class=1)\n",
    "trainer.load_train_data(file_path=negative_sample_path,data_type=\"*.jpg\",data_class=0)\n",
    "trainer.load_train_data(file_path=negative_sample_path,data_type=\"*.png\",data_class=0)\n",
    "\n",
    "trainer.train_svm(model_save_path=\"./data/models/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa1b0d5e-fea7-4f34-81a8-f25f1c404617",
   "metadata": {},
   "source": [
    "test_path=\"./data/rawdata/leftImg8bit/test/mainz\"\n",
    "# file_name=\"berlin_000122_000019_leftImg8bit.png\"\n",
    "\n",
    "file_name=['mainz_000001_044619_leftImg8bit.png','mainz_000001_041284_leftImg8bit.png','mainz_000001_041172_leftImg8bit.png']\n",
    "path_cell_16=\"./data/models/svm_model_13_12_2022_17_45_22.dat\"\n",
    "path_cell_08=\"./data/models/svm_model_28_11_2022_22_54_16.dat\"\n",
    "path_cell_04=\"./data/models/svm_model_13_12_2022_17_54_46.dat\"\n",
    "svm_classifier=PersonDetecor(path_test=test_path,path_anno=\"\",model_path=path_cell_08)\n",
    "svm_classifier.detect_persons_single(file_name=file_name[2],visualise=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c73464c-1a12-47df-baad-8235c95086df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
