{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbebf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Essential imports\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import cv2\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import copy \n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from imutils.object_detection import non_max_suppression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99548a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SvmTrainer():\n",
    "    def __init__(self):\n",
    "        ## Default values\n",
    "        print(f\"Staring the Classifier\")\n",
    "        self.train_data=[]\n",
    "        self.train_labels=[]\n",
    "        self.classifier=LinearSVC()\n",
    "    \n",
    "    def load_train_data(self,file_path,data_type=\"*.png\",data_class=1):\n",
    "        '''\n",
    "        Load the images from the filepath and get the HoG featues\n",
    "        If dataclass=1 positive images \n",
    "        If dataclass=0 negative images\n",
    "        '''\n",
    "        \n",
    "        for filename in glob.glob(os.path.join(file_path,data_type)):\n",
    "            current_image=cv2.imread(filename)\n",
    "            current_image=cv2.resize(current_image,(64,128))\n",
    "            current_image=hog(orientations=9,pixels_per_cell=(8,8),visualize=False,cells_per_block=(3,3))\n",
    "            self.train_data.append(current_image)\n",
    "            self.train_labels.append(data_type)\n",
    "            print(f\" HoG Feature extractor complete\")\n",
    "            \n",
    "    def train_svm(self,model_save_path='./'):\n",
    "        '''\n",
    "        This function calls for training the data set\n",
    "        '''\n",
    "        ## Asserts if there are training data\n",
    "        assert len(self.train_data)>0,f\"No training data available\"\n",
    "        # Convert to numpy arrays\n",
    "        self.train_data = np.float32(self.train_data)\n",
    "        self.train_labels= np.array(self.train_labels)\n",
    "        #Fitting the data\n",
    "        self.classifier.fit(self.train_data,self.train_labels)\n",
    "        print(f\"Training complete saving model at {model_save_path}\")\n",
    "        joblib.dump(self.classifier,'svm_model.dat')\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c5d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonDetecor():\n",
    "    def __init__(self,path_test: str,path_anno: str,model_path:str)-> None:\n",
    "        '''\n",
    "        Initiate the person detector class\n",
    "        \n",
    "        Params\n",
    "        ----------\n",
    "        path_test : Relative file path with the test images\n",
    "        path_anno : Relative path with the annotations \n",
    "        '''\n",
    "        self.path_test=path_test\n",
    "        self.path_anno=path_anno\n",
    "        self.downscale_factor=1.5\n",
    "        self.classifier=joblib.load(model_path)\n",
    "        # Size of the detections used in training \n",
    "        self.detect_size=(64,128)\n",
    "        self.step_size=(9,9)\n",
    "        ## The confusion matrix\n",
    "        ## TP,FP | FN , TN\n",
    "        self.CM=[[0,0],[0,0]]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def nms(self):\n",
    "        '''\n",
    "        Fast Non-maximum-supression method based on Malisiewicz et al \n",
    "                    \n",
    "        \n",
    "        \n",
    "        References:\n",
    "        The https://github.com/quantombone/exemplarsvm\n",
    "        https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/\n",
    "        https://pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "        https://nms.readthedocs.io/en/latest/_modules/nms/malisiewicz.html\n",
    "        '''\n",
    "        \n",
    "        raise NotImplementedError(\"Please implement the method\")\n",
    "        \n",
    "    def metrics(self,detections,ground_truths):\n",
    "        '''\n",
    "        Calculate the performance metrics of the method \n",
    "        \n",
    "        Measure following metrics         \n",
    "            meanAveragePrecision\n",
    "            average IoU\n",
    "            \n",
    "            \n",
    "        References:\n",
    "        https://towardsdatascience.com/on-object-detection-metrics-with-worked-example-216f173ed31e\n",
    "        https://www.v7labs.com/blog/mean-average-precision\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        ##IOU calculation\n",
    "        for detection in detections:            \n",
    "            x_mid=detection[0]+detection[2]/2\n",
    "            y_mid=detection[1]+detection[3]/2\n",
    "        for gt in ground_truths:\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        raise NotImplementedError(\"Implement me\")\n",
    "        \n",
    "    def sliding_window(self,image,window_size,step_size):\n",
    "        ''''\n",
    "        Sliding window approach to pass throught the image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        window_size: Tuple (2x2)\n",
    "                    The size of the window\n",
    "        \n",
    "        step_size : \n",
    "                            \n",
    "        \n",
    "                        the size of the window that wil p \n",
    "        Returns\n",
    "        -------\n",
    "        x : ndarray, shape Q\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        for x in range(0,image.shape[0],step_size[0]):\n",
    "            for y in range(0,image.shape[1],step_size[1]):\n",
    "                yield (x,y,image[x:window_size[0],y:window_size[1]])       \n",
    "        \n",
    "        \n",
    "    def visualise(self,image,bBox,confidence):\n",
    "        '''\n",
    "        Visualise the result bBox on image\n",
    "        '''\n",
    "        \n",
    "        figure1=plt.figure(figsize=(25,10))\n",
    "        ax1=figure1.add_subplot(111)\n",
    "        cv2.rectangle(image,(bBox[0],bBox[2]),(bBox[1],bBox[3]),(0,0,255),2)\n",
    "        cv2.putText(image,\"Confidence: \"+str(confidence),(bBox[0],bBox[2]-10))\n",
    "        ax1.imshow(image)\n",
    "        ax1.set(title=\"Prediction\",xlabel=\"X\",ylabel=\"Y\")     \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def detect_persons(self,data_type: str,metrics:bool=False,visualise:bool=False)-> None:\n",
    "        '''\n",
    "        Detect personson in images in a given folder \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        data_type: string\n",
    "                    the data type of images eg: png,jpeg\n",
    "        metrics  : bool\n",
    "                    Boolean to calculate metrics\n",
    "        visualise : bool\n",
    "                    Visualise the results\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        for filename in glob.glob(os.path.join(self.path_test,data_type)):\n",
    "            current_detections=[]\n",
    "            current_scale=0\n",
    "            current_image=cv2.imread(filename)\n",
    "            ## Maybe resize the image\n",
    "            \n",
    "            for scaled_image in pyramid_gaussian(current_image):\n",
    "                if scaled_image.shape[0]<self.detect_size[0] or scaled_image.shape[1]<self.detect_size[1]:\n",
    "                    #Loop breaks when the the scale reaches smaller than the images\n",
    "                    # that was used to train the classifier\n",
    "                    break\n",
    "                for (x,y,cropped_image) in sliding_window(scaled_image,self.detect_size,self.step_size):\n",
    "                    #Convert to Grayscale for preprocessing\n",
    "                    cropped_image=cv2.cvtColor(cropped_image,cv2.COLOR_BGR2GRAY)\n",
    "                    #Create HoG features\n",
    "                    hog_feature=hog(cropped_image,\n",
    "                                orientations=9,\n",
    "                                pixels_per_cell=(8, 8),\n",
    "                                cells_per_block=(3, 3),\n",
    "                                block_norm='L2-Hys',\n",
    "                                visualize=False,\n",
    "                                transform_sqrt=False,\n",
    "                                feature_vector=True,\n",
    "                                multichannel=None)\n",
    "                    # Flatten the features\n",
    "                    hog_feature=hog_feature.reshape(1,-1)\n",
    "                    # Pass it through the trained model\n",
    "                    prediction=self.classifier(hog_feature)\n",
    "                    current_confidence=self.classifier.decision_function(hog_feature)\n",
    "                    \n",
    "                    ##If person is detected with a confidence over 50%\n",
    "                    if (prediction==1) and (current_confidence>0.5):\n",
    "                            x=int(x * (self.downscale_factor**current_scale))\n",
    "                            y=int(y* (self.downscale_factor**current_scale))\n",
    "                            w=int(self.detect_size[0]*(self.downscale_factor**current_scale))\n",
    "                            h=int(self.detect_size[1]*(self.downscale_factor**current_scale))\n",
    "                            current_detections.append(x,y,w,h,current_confidence)\n",
    "                current_scale+=1\n",
    "            #End of current image detections\n",
    "            # If there are detections\n",
    "            if len(current_detections)>0:                \n",
    "                bBoxs=np.array([[x,y,x+w,y+h] for (x,y,w,h,_) in current_detections])\n",
    "                confidences=[conf in for (_,_,_,_,conf) in current_detections]\n",
    "                max_box=non_max_suppression(bBoxs,probs=confidences,overlapThresh=0.3)\n",
    "\n",
    "                \n",
    "                            \n",
    "                            \n",
    "                    \n",
    "                \n",
    "                    \n",
    "                   \n",
    "                    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d30b2e-1e06-4242-b3cc-6b1ab216a2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
